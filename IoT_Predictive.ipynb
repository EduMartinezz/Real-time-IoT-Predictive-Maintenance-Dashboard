{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CB-aH7ZeG3s",
        "outputId": "99625ddc-fe1f-4e12-d39d-8495aa65c02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 matplotlib==3.9.2 seaborn==0.13.2 joblib==1.4.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rt_maint.py\n",
        "import time\n",
        "import threading\n",
        "import queue\n",
        "from datetime import datetime, timezone\n",
        "import os\n",
        "import math\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# ---------------------------\n",
        "# Page setup\n",
        "# ---------------------------\n",
        "st.set_page_config(page_title=\"IoT Predictive Maintenance — Realtime\", layout=\"wide\")\n",
        "st.title(\"🔧 Real-Time IoT Predictive Maintenance Dashboard\")\n",
        "\n",
        "# ---------------------------\n",
        "# Config\n",
        "# ---------------------------\n",
        "FEATURES = [\"vibration\", \"temperature\", \"pressure\", \"rpm\"]\n",
        "STREAM_INTERVAL_SEC = 0.6         # simulated sampling interval\n",
        "WINDOW_SECONDS = 600              # keep ~10 min rolling window\n",
        "ALERT_COOLDOWN_SEC = 30           # seconds between alerts per sensor\n",
        "MODEL_PATH = \"rt_maint_pipeline.joblib\"\n",
        "\n",
        "# ---------------------------\n",
        "# Helpers\n",
        "# ---------------------------\n",
        "def robust_z(x, series):\n",
        "    \"\"\"Median Absolute Deviation z-score (robust to outliers).\"\"\"\n",
        "    med = np.nanmedian(series)\n",
        "    mad = np.nanmedian(np.abs(series - med)) or 1.0\n",
        "    return (x - med) / (1.4826 * mad)\n",
        "\n",
        "def ewma(arr, alpha=0.2):\n",
        "    if len(arr) == 0:\n",
        "        return np.nan\n",
        "    s = arr[0]\n",
        "    for v in arr[1:]:\n",
        "        s = alpha * v + (1 - alpha) * s\n",
        "    return s\n",
        "\n",
        "def psi(expected, actual, bins=10, eps=1e-9):\n",
        "    \"\"\"\n",
        "    Population Stability Index for drift (lower better; <0.1 good, 0.1-0.25 moderate, >0.25 large).\n",
        "    \"\"\"\n",
        "    expected = pd.Series(expected).dropna()\n",
        "    actual = pd.Series(actual).dropna()\n",
        "    if expected.empty or actual.empty:\n",
        "        return np.nan\n",
        "    qs = np.linspace(0, 1, bins + 1)\n",
        "    cuts = np.unique(np.quantile(expected, qs))\n",
        "    if len(cuts) < 3:\n",
        "        return 0.0\n",
        "    e_hist = np.histogram(expected, bins=cuts)[0] / max(len(expected), 1)\n",
        "    a_hist = np.histogram(actual, bins=cuts)[0] / max(len(actual), 1)\n",
        "    return float(np.sum((a_hist - e_hist) * np.log((a_hist + eps) / (e_hist + eps))))\n",
        "\n",
        "def make_baseline(n=2000, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    base = pd.DataFrame({\n",
        "        \"vibration\": rng.normal(0.35, 0.05, n),\n",
        "        \"temperature\": rng.normal(58, 2.5, n),\n",
        "        \"pressure\": rng.normal(3.2, 0.15, n),\n",
        "        \"rpm\": rng.normal(1400, 120, n),\n",
        "    })\n",
        "    return base\n",
        "\n",
        "# ---------- Plotting helper (dual axis) ----------\n",
        "def plot_dual_axis_time(t, y_left, y_right, title_left=\"Vibration & Temp (dual axis)\"):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    ln1 = ax1.plot(t, y_left, color=\"tab:blue\", label=\"vibration\")\n",
        "    ln2 = ax2.plot(t, y_right, color=\"orange\", label=\"temperature\")\n",
        "\n",
        "    ax1.set_ylabel(\"Vibration\", color=\"tab:blue\")\n",
        "    ax2.set_ylabel(\"Temperature\", color=\"orange\")\n",
        "    ax1.tick_params(axis=\"y\", colors=\"tab:blue\")\n",
        "    ax2.tick_params(axis=\"y\", colors=\"orange\")\n",
        "    ax1.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "    ax1.tick_params(axis=\"x\", rotation=30, labelsize=9)\n",
        "\n",
        "    ax1.set_title(title_left)\n",
        "    lines = ln1 + ln2\n",
        "    labels = [l.get_label() for l in lines]\n",
        "    ax1.legend(lines, labels, loc=\"best\", frameon=True, framealpha=0.85)\n",
        "    return fig\n",
        "\n",
        "# ---------------------------\n",
        "# Session state init\n",
        "# ---------------------------\n",
        "if \"stream_q\" not in st.session_state:\n",
        "    st.session_state.stream_q = queue.Queue(maxsize=10000)\n",
        "\n",
        "if \"live_df\" not in st.session_state:\n",
        "    st.session_state.live_df = pd.DataFrame(columns=[\"timestamp\", \"sensor_id\", *FEATURES])\n",
        "\n",
        "if \"alerts\" not in st.session_state:\n",
        "    st.session_state.alerts = []  # list of dicts\n",
        "\n",
        "if \"last_alert_time\" not in st.session_state:\n",
        "    st.session_state.last_alert_time = {}  # per sensor\n",
        "\n",
        "if \"baseline\" not in st.session_state:\n",
        "    st.session_state.baseline = make_baseline()\n",
        "\n",
        "if \"model\" not in st.session_state:\n",
        "    # Online-capable classifier\n",
        "    model = Pipeline([\n",
        "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
        "        (\"clf\", SGDClassifier(loss=\"log_loss\", alpha=1e-4, learning_rate=\"optimal\", random_state=123))\n",
        "    ])\n",
        "    st.session_state.model = model\n",
        "    st.session_state.model_classes = np.array([0, 1])\n",
        "    st.session_state.is_model_warm = False\n",
        "\n",
        "# ---------------------------\n",
        "# Simulator (background thread)\n",
        "# ---------------------------\n",
        "def sensor_simulator(out_q: queue.Queue, stop_event: threading.Event, n_sensors=4):\n",
        "    rng = np.random.default_rng(2025)\n",
        "    drift_start = time.time() + 90   # drift for S03 after 1.5 min\n",
        "    failure_rate = 0.05              # probability of weak label row\n",
        "\n",
        "    while not stop_event.is_set():\n",
        "        t_iso = datetime.now(timezone.utc).isoformat()\n",
        "        for sid in range(1, n_sensors + 1):\n",
        "            # Base signals\n",
        "            vibration = rng.normal(0.35, 0.05)\n",
        "            temperature = rng.normal(58, 2.5)\n",
        "            pressure = rng.normal(3.2, 0.15)\n",
        "            rpm = rng.normal(1400, 120)\n",
        "\n",
        "            # Spikes (demo)\n",
        "            if rng.random() < 0.15:\n",
        "                vibration += rng.normal(0.18, 0.05)\n",
        "                temperature += rng.normal(4.5, 1.0)\n",
        "\n",
        "            # Controlled drift on S03\n",
        "            if time.time() > drift_start and sid == 3:\n",
        "                vibration += 0.10\n",
        "                temperature += 1.2\n",
        "\n",
        "            row = {\n",
        "                \"timestamp\": t_iso,\n",
        "                \"sensor_id\": f\"S{sid:02d}\",\n",
        "                \"vibration\": float(vibration),\n",
        "                \"temperature\": float(temperature),\n",
        "                \"pressure\": float(pressure),\n",
        "                \"rpm\": float(rpm),\n",
        "            }\n",
        "\n",
        "            # Occasionally attach a weak label for online learning\n",
        "            if rng.random() < failure_rate:\n",
        "                row[\"label\"] = 1 if (row[\"vibration\"] > 0.42 or row[\"temperature\"] > 62.0) else 0\n",
        "\n",
        "            try:\n",
        "                out_q.put(row, timeout=0.01)\n",
        "            except queue.Full:\n",
        "                pass\n",
        "\n",
        "        time.sleep(STREAM_INTERVAL_SEC)\n",
        "\n",
        "if \"sim_stop\" not in st.session_state:\n",
        "    st.session_state.sim_stop = threading.Event()\n",
        "    st.session_state.sim_thread = threading.Thread(\n",
        "        target=sensor_simulator,\n",
        "        args=(st.session_state.stream_q, st.session_state.sim_stop),\n",
        "        daemon=True,\n",
        "    )\n",
        "    st.session_state.sim_thread.start()\n",
        "\n",
        "# ---------------------------\n",
        "# Sidebar Controls\n",
        "# ---------------------------\n",
        "st.sidebar.header(\"⚙️ Controls\")\n",
        "alert_threshold = st.sidebar.slider(\"Alert threshold (risk ≥)\", 0.10, 0.99, 0.70, 0.01)\n",
        "anomaly_weight = st.sidebar.slider(\"Anomaly weight (0→risk from model only, 1→anomaly only)\", 0.0, 1.0, 0.40, 0.05)\n",
        "train_rate = st.sidebar.slider(\"Online training rate (probability to partial_fit on labeled events)\", 0.0, 1.0, 0.35, 0.05)\n",
        "show_points = st.sidebar.slider(\"Plot last N points per sensor\", 100, 1500, 700, 50)\n",
        "\n",
        "colA, colB, colC = st.sidebar.columns(3)\n",
        "if colA.button(\"💾 Save\"):\n",
        "    joblib.dump(st.session_state.model, MODEL_PATH)\n",
        "    st.sidebar.success(f\"Saved → {MODEL_PATH}\")\n",
        "if colB.button(\"📂 Load\") and os.path.exists(MODEL_PATH):\n",
        "    st.session_state.model = joblib.load(MODEL_PATH)\n",
        "    st.sidebar.success(f\"Loaded ← {MODEL_PATH}\")\n",
        "if colC.button(\"🧹 Clear Alerts\"):\n",
        "    st.session_state.alerts = []\n",
        "    st.session_state.last_alert_time = {}\n",
        "\n",
        "# ---------------------------\n",
        "# Rolling store & features\n",
        "# ---------------------------\n",
        "def append_live(df, row):\n",
        "    st.session_state.live_df.loc[len(st.session_state.live_df)] = row\n",
        "\n",
        "def trim_window():\n",
        "    df = st.session_state.live_df\n",
        "    if df.empty:\n",
        "        return\n",
        "    ts = pd.to_datetime(df[\"timestamp\"], utc=True, errors=\"coerce\")\n",
        "    cutoff = pd.Timestamp.now(tz=\"UTC\") - pd.Timedelta(seconds=WINDOW_SECONDS)\n",
        "    st.session_state.live_df = df[ts >= cutoff].reset_index(drop=True)\n",
        "\n",
        "def engineer_features(df_win: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df_win.empty:\n",
        "        cols = [\"sensor_id\", \"timestamp\", *FEATURES, \"z_vib\", \"ewma_vib\", \"z_tmp\", \"ewma_tmp\"]\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    g = df_win.groupby(\"sensor_id\", group_keys=False)\n",
        "    def fe(gdf):\n",
        "        vib = gdf[\"vibration\"].values\n",
        "        tmp = gdf[\"temperature\"].values\n",
        "        return pd.DataFrame({\n",
        "            \"sensor_id\": gdf[\"sensor_id\"].values,\n",
        "            \"timestamp\": gdf[\"timestamp\"].values,\n",
        "            \"vibration\": gdf[\"vibration\"].values,\n",
        "            \"temperature\": gdf[\"temperature\"].values,\n",
        "            \"pressure\": gdf[\"pressure\"].values,\n",
        "            \"rpm\": gdf[\"rpm\"].values,\n",
        "            \"z_vib\": [robust_z(x, vib) for x in vib],\n",
        "            \"ewma_vib\": [ewma(vib[:i+1]) for i in range(len(vib))],\n",
        "            \"z_tmp\": [robust_z(x, tmp) for x in tmp],\n",
        "            \"ewma_tmp\": [ewma(tmp[:i+1]) for i in range(len(tmp))],\n",
        "        })\n",
        "    return g.apply(fe)\n",
        "\n",
        "def score_batch(fe_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if fe_df.empty:\n",
        "        return fe_df.assign(anomaly=[])\n",
        "    # anomaly score: sigmoid(|z_vib| + |z_tmp|)\n",
        "    zscore = np.abs(fe_df[\"z_vib\"].astype(float).values) + np.abs(fe_df[\"z_tmp\"].astype(float).values)\n",
        "    anomaly = 1 / (1 + np.exp(-zscore))\n",
        "    fe_df = fe_df.assign(anomaly=anomaly)\n",
        "\n",
        "    # supervised risk (if model is warm)\n",
        "    feats = [\"vibration\", \"temperature\", \"pressure\", \"rpm\", \"z_vib\", \"z_tmp\", \"ewma_vib\", \"ewma_tmp\"]\n",
        "    X = fe_df[feats].astype(float).values\n",
        "    if st.session_state.is_model_warm:\n",
        "        risk_sup = st.session_state.model.predict_proba(X)[:, 1]\n",
        "    else:\n",
        "        risk_sup = np.zeros(len(fe_df))\n",
        "    risk = anomaly_weight * anomaly + (1 - anomaly_weight) * risk_sup\n",
        "    return fe_df.assign(risk=risk, risk_sup=risk_sup)\n",
        "\n",
        "def maybe_train_online(fe_df: pd.DataFrame, raw_df: pd.DataFrame):\n",
        "    if \"label\" not in raw_df.columns or raw_df[\"label\"].isna().all():\n",
        "        return\n",
        "    lab = raw_df[[\"timestamp\", \"sensor_id\", \"label\"]].dropna()\n",
        "    if lab.empty:\n",
        "        return\n",
        "    df = fe_df.merge(lab, on=[\"timestamp\", \"sensor_id\"], how=\"inner\")\n",
        "    if df.empty:\n",
        "        return\n",
        "    # Subsample for online updates\n",
        "    mask = np.random.rand(len(df)) < train_rate\n",
        "    df = df[mask]\n",
        "    if df.empty:\n",
        "        return\n",
        "\n",
        "    feats = [\"vibration\", \"temperature\", \"pressure\", \"rpm\", \"z_vib\", \"z_tmp\", \"ewma_vib\", \"ewma_tmp\"]\n",
        "    X = df[feats].astype(float).values\n",
        "    y = df[\"label\"].astype(int).values\n",
        "\n",
        "    scaler = st.session_state.model.named_steps[\"scaler\"]\n",
        "    clf = st.session_state.model.named_steps[\"clf\"]\n",
        "\n",
        "    # first call needs classes\n",
        "    Xs = scaler.fit_transform(X)\n",
        "    clf.partial_fit(Xs, y, classes=st.session_state.model_classes)\n",
        "    st.session_state.is_model_warm = True\n",
        "\n",
        "def add_alerts(risk_df: pd.DataFrame):\n",
        "    if risk_df.empty:\n",
        "        return\n",
        "    now = time.time()\n",
        "    for sid, grp in risk_df.groupby(\"sensor_id\"):\n",
        "        last = grp.tail(1).iloc[0]\n",
        "        risk = float(last[\"risk\"])\n",
        "        if risk >= alert_threshold:\n",
        "            last_t = st.session_state.last_alert_time.get(sid, 0)\n",
        "            if now - last_t >= ALERT_COOLDOWN_SEC:\n",
        "                st.session_state.alerts.append({\n",
        "                    \"time\": last[\"timestamp\"],\n",
        "                    \"sensor_id\": sid,\n",
        "                    \"risk\": round(risk, 3),\n",
        "                    \"vibration\": round(float(last[\"vibration\"]), 3),\n",
        "                    \"temperature\": round(float(last[\"temperature\"]), 2),\n",
        "                })\n",
        "                st.session_state.last_alert_time[sid] = now\n",
        "\n",
        "# ---------------------------\n",
        "# Drain → store → features → score → train → alerts\n",
        "# ---------------------------\n",
        "batch_rows = []\n",
        "while not st.session_state.stream_q.empty():\n",
        "    try:\n",
        "        batch_rows.append(st.session_state.stream_q.get_nowait())\n",
        "    except queue.Empty:\n",
        "        break\n",
        "\n",
        "if batch_rows:\n",
        "    raw_batch = pd.DataFrame(batch_rows)\n",
        "    for _, r in raw_batch.iterrows():\n",
        "        append_live(st.session_state.live_df, r)\n",
        "    trim_window()\n",
        "    fe = engineer_features(st.session_state.live_df)\n",
        "    scored = score_batch(fe)\n",
        "    maybe_train_online(fe, raw_batch)\n",
        "    add_alerts(scored)\n",
        "else:\n",
        "    fe = engineer_features(st.session_state.live_df)\n",
        "    scored = score_batch(fe)\n",
        "\n",
        "# ---------------------------\n",
        "# Sidebar KPIs (live)\n",
        "# ---------------------------\n",
        "st.sidebar.divider()\n",
        "st.sidebar.subheader(\"📊 Live KPIs\")\n",
        "\n",
        "# Always show alert counter\n",
        "st.sidebar.metric(\"Active Alerts\", len(st.session_state.alerts))\n",
        "\n",
        "# Show risk KPIs if we have scored data\n",
        "if not scored.empty:\n",
        "    latest_per = (\n",
        "        scored.groupby(\"sensor_id\", as_index=False)\n",
        "              .tail(1)\n",
        "              .sort_values(\"sensor_id\")\n",
        "              .reset_index(drop=True)\n",
        "    )\n",
        "    avg_risk = float(latest_per[\"risk\"].mean())\n",
        "    max_idx = int(latest_per[\"risk\"].idxmax())\n",
        "    max_risk = float(latest_per.loc[max_idx, \"risk\"])\n",
        "    worst_sensor = str(latest_per.loc[max_idx, \"sensor_id\"])\n",
        "\n",
        "    st.sidebar.metric(\"Avg Risk (latest)\", f\"{avg_risk:.2f}\")\n",
        "    st.sidebar.metric(\"Max Risk (latest)\", f\"{max_risk:.2f}\")\n",
        "    st.sidebar.caption(f\"Worst sensor right now: **{worst_sensor}**\")\n",
        "\n",
        "    # (Optional) Per-sensor mini KPIs\n",
        "    with st.sidebar.expander(\"Per-sensor risk (latest)\"):\n",
        "        for _, row in latest_per.iterrows():\n",
        "            sid = row[\"sensor_id\"]\n",
        "            r = float(row[\"risk\"])\n",
        "            st.write(f\"**{sid}** — {r:.2f}\")\n",
        "else:\n",
        "    st.sidebar.caption(\"Waiting for data to compute risk KPIs…\")\n",
        "# ---------------------------\n",
        "# UI Tabs\n",
        "# ---------------------------\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\"📈 Live Monitor\", \"🚨 Alerts\", \"🧠 Model\", \"🧪 Data Quality & Drift\"])\n",
        "\n",
        "# ---------- Live Monitor ----------\n",
        "with tab1:\n",
        "    st.subheader(\"Live Signals & Risk\")\n",
        "    if scored.empty:\n",
        "        st.info(\"Waiting for stream…\")\n",
        "    else:\n",
        "        latest = scored.groupby(\"sensor_id\", as_index=False).tail(1).sort_values(\"sensor_id\")\n",
        "        st.dataframe(\n",
        "            latest[[\"timestamp\", \"sensor_id\", \"vibration\", \"temperature\", \"pressure\", \"rpm\", \"anomaly\", \"risk\"]]\n",
        "            .assign(risk=lambda d: d[\"risk\"].round(3), anomaly=lambda d: d[\"anomaly\"].round(3))\n",
        "        )\n",
        "\n",
        "        for sid, g in scored.groupby(\"sensor_id\"):\n",
        "            g = g.tail(show_points)\n",
        "            st.markdown(f\"**Sensor {sid}**\")\n",
        "            c1, c2 = st.columns(2)\n",
        "\n",
        "            t = pd.to_datetime(g[\"timestamp\"], utc=True, errors=\"coerce\")\n",
        "\n",
        "            # Left: dual-axis line plot\n",
        "            with c1:\n",
        "                fig = plot_dual_axis_time(\n",
        "                    t,\n",
        "                    g[\"vibration\"].values,\n",
        "                    g[\"temperature\"].values,\n",
        "                    title_left=f\"{sid} — Vibration & Temp (dual axis)\",\n",
        "                )\n",
        "                st.pyplot(fig)\n",
        "\n",
        "            # Right: risk + threshold\n",
        "            with c2:\n",
        "                fig, ax = plt.subplots()\n",
        "                ax.plot(t, g[\"risk\"], label=\"risk\")\n",
        "                ax.axhline(alert_threshold, linestyle=\"--\", linewidth=1)\n",
        "                ax.set_ylim(0, 1.05)\n",
        "                ax.set_title(f\"{sid} — Risk\")\n",
        "                ax.legend(loc=\"best\", frameon=True, framealpha=0.85)\n",
        "                ax.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
        "                ax.tick_params(axis=\"x\", rotation=30, labelsize=9)\n",
        "                st.pyplot(fig)\n",
        "\n",
        "# ---------- Alerts ----------\n",
        "with tab2:\n",
        "    st.subheader(\"Active Alerts\")\n",
        "    if not st.session_state.alerts:\n",
        "        st.success(\"No alerts. All sensors nominal.\")\n",
        "    else:\n",
        "        st.dataframe(pd.DataFrame(st.session_state.alerts).iloc[::-1].reset_index(drop=True))\n",
        "\n",
        "# ---------- Model ----------\n",
        "with tab3:\n",
        "    st.subheader(\"Online Model Status\")\n",
        "    st.write(f\"Warm-started: **{st.session_state.is_model_warm}**\")\n",
        "    st.caption(\"The classifier updates online when labeled events trickle in (simulated).\")\n",
        "    # Simple proxy PR curve on the latest window: use top-k risk as positives\n",
        "    if not scored.empty:\n",
        "        try:\n",
        "            y_scores = scored[\"risk\"].values\n",
        "            k = max(5, int(0.1 * len(y_scores)))\n",
        "            proxy_y = np.zeros_like(y_scores, dtype=int)\n",
        "            proxy_y[np.argsort(y_scores)[-k:]] = 1\n",
        "            P, R, T = precision_recall_curve(proxy_y, y_scores)\n",
        "            f1 = 2 * (P * R) / np.clip(P + R, 1e-9, None)\n",
        "            if len(T) > 0:\n",
        "                best = int(np.nanargmax(f1[:-1]))\n",
        "                st.info(f\"Window-suggested threshold ≈ **{T[best]:.2f}** (proxy F1≈{f1[best]:.2f})\")\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.plot(R, P)\n",
        "            ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\"); ax.set_title(\"Proxy Precision–Recall (Risk Top-k as Positives)\")\n",
        "            st.pyplot(fig)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# ---------- Data Quality & Drift ----------\n",
        "with tab4:\n",
        "    st.subheader(\"Data Quality\")\n",
        "    if st.session_state.live_df.empty:\n",
        "        st.info(\"Waiting for stream…\")\n",
        "    else:\n",
        "        dfq = st.session_state.live_df\n",
        "        dq_rows = []\n",
        "        for sid, g in dfq.groupby(\"sensor_id\"):\n",
        "            last = g.tail(200)\n",
        "            spikes = ((last[\"vibration\"] - last[\"vibration\"].rolling(5, min_periods=1).mean()).abs() > 0.2).sum()\n",
        "            dq_rows.append({\n",
        "                \"sensor_id\": sid,\n",
        "                \"n_last\": len(last),\n",
        "                \"missing_any\": int(last[FEATURES].isna().any().any()),\n",
        "                \"flatlines_vibration\": int(last[\"vibration\"].nunique() < 5),\n",
        "                \"spikes_vibration\": int(spikes > 3),\n",
        "            })\n",
        "        st.dataframe(pd.DataFrame(dq_rows))\n",
        "\n",
        "        st.subheader(\"Drift (PSI vs Baseline)\")\n",
        "        psi_rows = []\n",
        "        base = st.session_state.baseline\n",
        "        cur = dfq.tail(1500)\n",
        "        for col in FEATURES:\n",
        "            val = psi(base[col], cur[col])\n",
        "            psi_rows.append({\"feature\": col, \"psi\": round(val if pd.notna(val) else 0.0, 3)})\n",
        "        st.dataframe(pd.DataFrame(psi_rows))\n",
        "        st.caption(\"Heuristic: PSI < 0.10 stable • 0.10–0.25 moderate shift • >0.25 significant shift.\")\n",
        "\n",
        "st.caption(\"Demo: simulator emits sensor events; the app maintains a rolling window, computes features, blends anomaly + online risk, triggers alerts, and tracks drift & data quality.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hir7x0MzeTZ1",
        "outputId": "66976f96-91a3-4dd0-e033-a88910a033c5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rt_maint.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install streamlit pyngrok==7.1.6\n",
        "!pkill -f streamlit || true\n",
        "!streamlit run app_churn.py --server.port 8501 &>/content/logs.txt &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvLzMlyzegC4",
        "outputId": "3af3e332-7584-4c17-fa2e-e4142dc00dc3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os, time\n",
        "os.environ[\"NGROK_TOKEN\"] = \"2tZ6mqHFZ9n2B4HsTOzAPVA3Jnw_6qB1RFncPLxV8kcYUxNcJ\"\n",
        "ngrok.set_auth_token(os.environ[\"NGROK_TOKEN\"])\n",
        "time.sleep(2)\n",
        "print(\"URL:\", ngrok.connect(8501, \"http\").public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QznlQ5jde5ot",
        "outputId": "ee5e5079-f87e-4cbc-d562-653cef8574ea"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://5bc312c70faa.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}